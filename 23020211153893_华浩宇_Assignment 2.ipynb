{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2: DenseNet with CIFAR10 Dataset by TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, you are required to implement DenseNet to classify images from the [CIFAR10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html) by using TensorFlow with Keras. DenseNet is very well-known and therefore it has been implemented and pre-trained by Keras. You are also required to load and test the pre-trained models, and compare them with your models.\n",
    "\n",
    "First of all, read the DenseNet paper. DenseNet was originally proposed in 2016 by Gao Huang, Zhuang Liu, Laurens van der Maaten, Kilian Q. Weinberger in the following paper:\n",
    "https://arxiv.org/abs/1608.06993\n",
    "\n",
    "The process will be broken down into the following steps:\n",
    ">\n",
    "1. Answer a short question about DenseNet. (10 marks)\n",
    "2. Load and visualize the data.\n",
    "3. Implement your models. (30 marks)\n",
    "4. Train and evaluate your models. (25 marks)\n",
    "5. Load the pre-trained models from Keras and evaluate them. (15 marks)\n",
    "6. Analysis your results. (20 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Answer a short question (20 marks)\n",
    "\n",
    "Now that you know what DenseNet is all about, let's compare it to VGG.\n",
    "Both VGG and DenseNet papers describe several variations of their models that differ by their depth.\n",
    "For example, VGG16 and VGG19, DenseNet-121 and DenseNet-169 are four examples from these papers.\n",
    "\n",
    "Aside from difference in network depth, how is the architecture of DenseNet different from that of VGG? Please enter your answer in the next cell (approximately 100-200 words, both English and Chinese are acceptable)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write your answer in this cell.**\n",
    "VGGNet的主要特点就是小卷积核和更深层次的网络，Densenet解决了深层的网络难以训练和梯度消失的问题，DenseNet基于与其多次学习冗余的特征,特征复用是一种更好的特征提取方式的假设.提出了一个激进的密集连接机制：即互相连接所有的层，具体来说就是每个层都会接受其前面所有层作为其额外的输入。这种直接concat来自不同层的特征图的方法，这可以实现特征重用，提升效率，但这种激进的做法也有显存占用高的缺点，但瑕不掩瑜，DenseNet缓解了梯度消失问题，加强了特征传播和特征复用，极大的减少了参数量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Load and visualize the data.\n",
    "\n",
    "The data is directly loaded into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-03 10:25:08.220251: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "y_train shape: (50000, 1)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "num_classes = 10\n",
    "\n",
    "# load the CIFAR10 data\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# input image dimensions\n",
    "input_shape = x_train.shape[1:]\n",
    "\n",
    "# mormalize data\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "print('y_train shape:', y_train.shape)\n",
    "\n",
    "# convert class vectors to binary class matrices.\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f5c999d94c0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Implement your models (30 marks)\n",
    "\n",
    "In this task, you are required to implement DenseNet-73 and DenseNet-93 with compression and bottleneck as depicted in the original paper. DenseNet-73 and DenseNet-93 follow the architecture of DenseNet and remove several convolution layers for time efficiency. Specifically, DenseNet-73 and DenseNet-93 have a group of 4 Dense Block, each has a set of [4,8,12,10] and [4,8,16,16] mini-block including a 1x1 conv follow by a 3x3 conv. For more details, please refer to Table 1 in the original paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.layers as layers\n",
    "\n",
    "\n",
    "def conv_block(x, growth_rate, name):\n",
    "    # axis的值取决于按照input的哪一个维度进行BN,\n",
    "    x1 = layers.BatchNormalization(axis=3)(x)\n",
    "    x1 = layers.LeakyReLU(alpha=0.2)(x1)\n",
    "    # 第一个参数代表Filter/Kernel的个数，等于卷积后的输出通道数\n",
    "    # 第二个位置代表卷积核尺寸，用两个整数的元组或者列表表示，用单个正数表示为所有的空间维度指定相同的值\n",
    "    x1 = layers.Conv2D(2 * growth_rate, 1, use_bias=False, name=name + '_1_conv')(x1)\n",
    "    x1 = layers.BatchNormalization(axis=3)(x1)\n",
    "    x1 = layers.LeakyReLU(alpha=0.2, name=name + '_1_leakyRelu')(x1)\n",
    "    x1 = layers.Conv2D(growth_rate, 3, padding='same', use_bias=False, name=name + '_2_conv')(x1)\n",
    "    x = layers.Concatenate(name=name + '_concat')([x, x1])\n",
    "    return x\n",
    "\n",
    "\n",
    "def dense_block(x, blocks, name, growth_rate=32):\n",
    "    for i in range(blocks):\n",
    "        x = conv_block(x, growth_rate, name=name + '_block' + str(i + 1))\n",
    "    return x\n",
    "\n",
    "\n",
    "def transition_block(x, reduction, name):\n",
    "    x = layers.BatchNormalization(axis=3, name=name + '_bn')(x)\n",
    "    x = layers.LeakyReLU(alpha=0.2, name=name + '_leakyRelu')(x)\n",
    "    x = layers.Conv2D(int(x.shape[3] * reduction), 1, use_bias=False, name=name + '_conv')(x)\n",
    "    # pool_size：一个整数或者2个整数的元组/列表：（pool_height，pool_width）\n",
    "    # 指定池化窗口的大小。 可以是单个整数，以为所有空间维度指定相同值\n",
    "    # strides：一个整数或者2个整数的元组 / 列表\n",
    "    # 指定池操作的步幅。 可以是单个整数，以为所有空间维度指定相同值\n",
    "    x = layers.AveragePooling2D(2, strides=2, name=name + '_pool')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def my_densenet(blocks):\n",
    "    inputs = keras.Input(shape=(32, 32, 3), name='img')\n",
    "    x = layers.Conv2D(filters=16, kernel_size=(3, 3), strides=(1, 1), padding='same')(inputs)\n",
    "    x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "    x = dense_block(x, blocks[0], name='conv1', growth_rate=32)\n",
    "    x = transition_block(x, 0.5, name='pool1')\n",
    "    x = dense_block(x, blocks[1], name='conv2', growth_rate=32)\n",
    "    x = transition_block(x, 0.5, name='pool2')\n",
    "    x = dense_block(x, blocks[2], name='conv3', growth_rate=32)\n",
    "    x = transition_block(x, 0.5, name='pool3')\n",
    "    x = dense_block(x, blocks[3], name='conv4', growth_rate=32)\n",
    "    x = layers.BatchNormalization(axis=3, name='bn')(x)\n",
    "    x = layers.LeakyReLU(alpha=0.2, name='leakyRelu')(x)\n",
    "    x = layers.GlobalAvgPool2D(name='avg_pool')(x)\n",
    "    x = layers.Dense(10, activation='softmax', name='fc')(x)\n",
    "    model = keras.Model(inputs, x, name='densenet_73')\n",
    "    return model\n",
    "\n",
    "\n",
    "def my_model(blocks=(4, 8, 12, 10)):\n",
    "    denseNet = my_densenet(blocks)\n",
    "    denseNet.compile(optimizer=keras.optimizers.Adam(),\n",
    "                     loss='categorical_crossentropy',\n",
    "                     metrics=['accuracy'])\n",
    "    denseNet.summary()\n",
    "    return denseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-03 10:25:11.149807: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-11-03 10:25:11.150698: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2021-11-03 10:25:12.536959: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:02:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2021-11-03 10:25:12.538445: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "pciBusID: 0000:82:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2021-11-03 10:25:12.538489: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-11-03 10:25:12.541821: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2021-11-03 10:25:12.541895: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2021-11-03 10:25:12.544728: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-11-03 10:25:12.545256: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-11-03 10:25:12.548418: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-11-03 10:25:12.550285: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-11-03 10:25:12.557269: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-11-03 10:25:12.562203: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1\n",
      "2021-11-03 10:25:12.562899: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-03 10:25:12.825794: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:02:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2021-11-03 10:25:12.826849: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "pciBusID: 0000:82:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2021-11-03 10:25:12.826891: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-11-03 10:25:12.826933: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2021-11-03 10:25:12.826953: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2021-11-03 10:25:12.826971: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-11-03 10:25:12.826989: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-11-03 10:25:12.827007: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-11-03 10:25:12.827025: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-11-03 10:25:12.827043: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-11-03 10:25:12.830691: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1\n",
      "2021-11-03 10:25:12.830744: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-11-03 10:25:13.780540: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-11-03 10:25:13.780581: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 1 \n",
      "2021-11-03 10:25:13.780586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N N \n",
      "2021-11-03 10:25:13.780589: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 1:   N N \n",
      "2021-11-03 10:25:13.783173: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10074 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:02:00.0, compute capability: 7.5)\n",
      "2021-11-03 10:25:13.787190: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10074 MB memory) -> physical GPU (device: 1, name: GeForce RTX 2080 Ti, pci bus id: 0000:82:00.0, compute capability: 7.5)\n",
      "2021-11-03 10:25:13.787679: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"densenet_73\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "img (InputLayer)                [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 32, 32, 16)   448         img[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)         (None, 32, 32, 16)   0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 32, 32, 16)   64          leaky_re_lu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 32, 32, 16)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1_block1_1_conv (Conv2D)    (None, 32, 32, 64)   1024        leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 64)   256         conv1_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1_block1_1_leakyRelu (Leaky (None, 32, 32, 64)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1_block1_2_conv (Conv2D)    (None, 32, 32, 32)   18432       conv1_block1_1_leakyRelu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv1_block1_concat (Concatenat (None, 32, 32, 48)   0           leaky_re_lu[0][0]                \n",
      "                                                                 conv1_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 48)   192         conv1_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 32, 32, 48)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1_block2_1_conv (Conv2D)    (None, 32, 32, 64)   3072        leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 64)   256         conv1_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1_block2_1_leakyRelu (Leaky (None, 32, 32, 64)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1_block2_2_conv (Conv2D)    (None, 32, 32, 32)   18432       conv1_block2_1_leakyRelu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv1_block2_concat (Concatenat (None, 32, 32, 80)   0           conv1_block1_concat[0][0]        \n",
      "                                                                 conv1_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 32, 80)   320         conv1_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 32, 32, 80)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1_block3_1_conv (Conv2D)    (None, 32, 32, 64)   5120        leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 32, 64)   256         conv1_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1_block3_1_leakyRelu (Leaky (None, 32, 32, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1_block3_2_conv (Conv2D)    (None, 32, 32, 32)   18432       conv1_block3_1_leakyRelu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv1_block3_concat (Concatenat (None, 32, 32, 112)  0           conv1_block2_concat[0][0]        \n",
      "                                                                 conv1_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 32, 32, 112)  448         conv1_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 32, 32, 112)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1_block4_1_conv (Conv2D)    (None, 32, 32, 64)   7168        leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32, 32, 64)   256         conv1_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1_block4_1_leakyRelu (Leaky (None, 32, 32, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1_block4_2_conv (Conv2D)    (None, 32, 32, 32)   18432       conv1_block4_1_leakyRelu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv1_block4_concat (Concatenat (None, 32, 32, 144)  0           conv1_block3_concat[0][0]        \n",
      "                                                                 conv1_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool1_bn (BatchNormalization)   (None, 32, 32, 144)  576         conv1_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool1_leakyRelu (LeakyReLU)     (None, 32, 32, 144)  0           pool1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_conv (Conv2D)             (None, 32, 32, 72)   10368       pool1_leakyRelu[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (AveragePooling2D)   (None, 16, 16, 72)   0           pool1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 16, 16, 72)   288         pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 16, 16, 72)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 16, 16, 64)   4608        leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 16, 16, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_leakyRelu (Leaky (None, 16, 16, 64)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 16, 16, 32)   18432       conv2_block1_1_leakyRelu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_concat (Concatenat (None, 16, 16, 104)  0           pool1_pool[0][0]                 \n",
      "                                                                 conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 16, 16, 104)  416         conv2_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 16, 16, 104)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 16, 16, 64)   6656        leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 16, 16, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_leakyRelu (Leaky (None, 16, 16, 64)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 16, 16, 32)   18432       conv2_block2_1_leakyRelu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_concat (Concatenat (None, 16, 16, 136)  0           conv2_block1_concat[0][0]        \n",
      "                                                                 conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 16, 16, 136)  544         conv2_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 16, 16, 136)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 16, 16, 64)   8704        leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 16, 16, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_leakyRelu (Leaky (None, 16, 16, 64)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 16, 16, 32)   18432       conv2_block3_1_leakyRelu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_concat (Concatenat (None, 16, 16, 168)  0           conv2_block2_concat[0][0]        \n",
      "                                                                 conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 16, 16, 168)  672         conv2_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, 16, 16, 168)  0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_conv (Conv2D)    (None, 16, 16, 64)   10752       leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 16, 16, 64)   256         conv2_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_leakyRelu (Leaky (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_2_conv (Conv2D)    (None, 16, 16, 32)   18432       conv2_block4_1_leakyRelu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_concat (Concatenat (None, 16, 16, 200)  0           conv2_block3_concat[0][0]        \n",
      "                                                                 conv2_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 16, 16, 200)  800         conv2_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, 16, 16, 200)  0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_conv (Conv2D)    (None, 16, 16, 64)   12800       leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 16, 16, 64)   256         conv2_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_leakyRelu (Leaky (None, 16, 16, 64)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_2_conv (Conv2D)    (None, 16, 16, 32)   18432       conv2_block5_1_leakyRelu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_concat (Concatenat (None, 16, 16, 232)  0           conv2_block4_concat[0][0]        \n",
      "                                                                 conv2_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 16, 16, 232)  928         conv2_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, 16, 16, 232)  0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_conv (Conv2D)    (None, 16, 16, 64)   14848       leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 16, 16, 64)   256         conv2_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_leakyRelu (Leaky (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_2_conv (Conv2D)    (None, 16, 16, 32)   18432       conv2_block6_1_leakyRelu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_concat (Concatenat (None, 16, 16, 264)  0           conv2_block5_concat[0][0]        \n",
      "                                                                 conv2_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 16, 16, 264)  1056        conv2_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)      (None, 16, 16, 264)  0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block7_1_conv (Conv2D)    (None, 16, 16, 64)   16896       leaky_re_lu_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 16, 16, 64)   256         conv2_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block7_1_leakyRelu (Leaky (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block7_2_conv (Conv2D)    (None, 16, 16, 32)   18432       conv2_block7_1_leakyRelu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block7_concat (Concatenat (None, 16, 16, 296)  0           conv2_block6_concat[0][0]        \n",
      "                                                                 conv2_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 16, 16, 296)  1184        conv2_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)      (None, 16, 16, 296)  0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block8_1_conv (Conv2D)    (None, 16, 16, 64)   18944       leaky_re_lu_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 16, 16, 64)   256         conv2_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block8_1_leakyRelu (Leaky (None, 16, 16, 64)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block8_2_conv (Conv2D)    (None, 16, 16, 32)   18432       conv2_block8_1_leakyRelu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block8_concat (Concatenat (None, 16, 16, 328)  0           conv2_block7_concat[0][0]        \n",
      "                                                                 conv2_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_bn (BatchNormalization)   (None, 16, 16, 328)  1312        conv2_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_leakyRelu (LeakyReLU)     (None, 16, 16, 328)  0           pool2_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool2_conv (Conv2D)             (None, 16, 16, 164)  53792       pool2_leakyRelu[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "pool2_pool (AveragePooling2D)   (None, 8, 8, 164)    0           pool2_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 8, 8, 164)    656         pool2_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)      (None, 8, 8, 164)    0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 8, 8, 64)     10496       leaky_re_lu_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 8, 8, 64)     256         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_leakyRelu (Leaky (None, 8, 8, 64)     0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 8, 8, 32)     18432       conv3_block1_1_leakyRelu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_concat (Concatenat (None, 8, 8, 196)    0           pool2_pool[0][0]                 \n",
      "                                                                 conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 8, 8, 196)    784         conv3_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)      (None, 8, 8, 196)    0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 8, 8, 64)     12544       leaky_re_lu_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 8, 8, 64)     256         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_leakyRelu (Leaky (None, 8, 8, 64)     0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 8, 8, 32)     18432       conv3_block2_1_leakyRelu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_concat (Concatenat (None, 8, 8, 228)    0           conv3_block1_concat[0][0]        \n",
      "                                                                 conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 8, 8, 228)    912         conv3_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)      (None, 8, 8, 228)    0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 8, 8, 64)     14592       leaky_re_lu_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 8, 8, 64)     256         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_leakyRelu (Leaky (None, 8, 8, 64)     0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 8, 8, 32)     18432       conv3_block3_1_leakyRelu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_concat (Concatenat (None, 8, 8, 260)    0           conv3_block2_concat[0][0]        \n",
      "                                                                 conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 8, 8, 260)    1040        conv3_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)      (None, 8, 8, 260)    0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 8, 8, 64)     16640       leaky_re_lu_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 8, 8, 64)     256         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_leakyRelu (Leaky (None, 8, 8, 64)     0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 8, 8, 32)     18432       conv3_block4_1_leakyRelu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_concat (Concatenat (None, 8, 8, 292)    0           conv3_block3_concat[0][0]        \n",
      "                                                                 conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 8, 8, 292)    1168        conv3_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)      (None, 8, 8, 292)    0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_conv (Conv2D)    (None, 8, 8, 64)     18688       leaky_re_lu_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 8, 8, 64)     256         conv3_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_leakyRelu (Leaky (None, 8, 8, 64)     0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_2_conv (Conv2D)    (None, 8, 8, 32)     18432       conv3_block5_1_leakyRelu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_concat (Concatenat (None, 8, 8, 324)    0           conv3_block4_concat[0][0]        \n",
      "                                                                 conv3_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 8, 8, 324)    1296        conv3_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)      (None, 8, 8, 324)    0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_conv (Conv2D)    (None, 8, 8, 64)     20736       leaky_re_lu_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 8, 8, 64)     256         conv3_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_leakyRelu (Leaky (None, 8, 8, 64)     0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_2_conv (Conv2D)    (None, 8, 8, 32)     18432       conv3_block6_1_leakyRelu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_concat (Concatenat (None, 8, 8, 356)    0           conv3_block5_concat[0][0]        \n",
      "                                                                 conv3_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 8, 8, 356)    1424        conv3_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)      (None, 8, 8, 356)    0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_conv (Conv2D)    (None, 8, 8, 64)     22784       leaky_re_lu_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 8, 8, 64)     256         conv3_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_leakyRelu (Leaky (None, 8, 8, 64)     0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_2_conv (Conv2D)    (None, 8, 8, 32)     18432       conv3_block7_1_leakyRelu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_concat (Concatenat (None, 8, 8, 388)    0           conv3_block6_concat[0][0]        \n",
      "                                                                 conv3_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 8, 8, 388)    1552        conv3_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)      (None, 8, 8, 388)    0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_conv (Conv2D)    (None, 8, 8, 64)     24832       leaky_re_lu_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 8, 8, 64)     256         conv3_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_leakyRelu (Leaky (None, 8, 8, 64)     0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_2_conv (Conv2D)    (None, 8, 8, 32)     18432       conv3_block8_1_leakyRelu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_concat (Concatenat (None, 8, 8, 420)    0           conv3_block7_concat[0][0]        \n",
      "                                                                 conv3_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 8, 8, 420)    1680        conv3_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)      (None, 8, 8, 420)    0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_conv (Conv2D)    (None, 8, 8, 64)     26880       leaky_re_lu_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 8, 8, 64)     256         conv3_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_leakyRelu (Leaky (None, 8, 8, 64)     0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_2_conv (Conv2D)    (None, 8, 8, 32)     18432       conv3_block9_1_leakyRelu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_concat (Concatenat (None, 8, 8, 452)    0           conv3_block8_concat[0][0]        \n",
      "                                                                 conv3_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 8, 8, 452)    1808        conv3_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_22 (LeakyReLU)      (None, 8, 8, 452)    0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_conv (Conv2D)   (None, 8, 8, 64)     28928       leaky_re_lu_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 8, 8, 64)     256         conv3_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_leakyRelu (Leak (None, 8, 8, 64)     0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_2_conv (Conv2D)   (None, 8, 8, 32)     18432       conv3_block10_1_leakyRelu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_concat (Concatena (None, 8, 8, 484)    0           conv3_block9_concat[0][0]        \n",
      "                                                                 conv3_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 8, 8, 484)    1936        conv3_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_23 (LeakyReLU)      (None, 8, 8, 484)    0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_conv (Conv2D)   (None, 8, 8, 64)     30976       leaky_re_lu_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 8, 8, 64)     256         conv3_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_leakyRelu (Leak (None, 8, 8, 64)     0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_2_conv (Conv2D)   (None, 8, 8, 32)     18432       conv3_block11_1_leakyRelu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_concat (Concatena (None, 8, 8, 516)    0           conv3_block10_concat[0][0]       \n",
      "                                                                 conv3_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 8, 8, 516)    2064        conv3_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_24 (LeakyReLU)      (None, 8, 8, 516)    0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_conv (Conv2D)   (None, 8, 8, 64)     33024       leaky_re_lu_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 8, 8, 64)     256         conv3_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_leakyRelu (Leak (None, 8, 8, 64)     0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_2_conv (Conv2D)   (None, 8, 8, 32)     18432       conv3_block12_1_leakyRelu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_concat (Concatena (None, 8, 8, 548)    0           conv3_block11_concat[0][0]       \n",
      "                                                                 conv3_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_bn (BatchNormalization)   (None, 8, 8, 548)    2192        conv3_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_leakyRelu (LeakyReLU)     (None, 8, 8, 548)    0           pool3_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool3_conv (Conv2D)             (None, 8, 8, 274)    150152      pool3_leakyRelu[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "pool3_pool (AveragePooling2D)   (None, 4, 4, 274)    0           pool3_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 4, 4, 274)    1096        pool3_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_25 (LeakyReLU)      (None, 4, 4, 274)    0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 4, 4, 64)     17536       leaky_re_lu_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 4, 4, 64)     256         conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_leakyRelu (Leaky (None, 4, 4, 64)     0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 4, 4, 32)     18432       conv4_block1_1_leakyRelu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_concat (Concatenat (None, 4, 4, 306)    0           pool3_pool[0][0]                 \n",
      "                                                                 conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 4, 4, 306)    1224        conv4_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_26 (LeakyReLU)      (None, 4, 4, 306)    0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 4, 4, 64)     19584       leaky_re_lu_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 4, 4, 64)     256         conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_leakyRelu (Leaky (None, 4, 4, 64)     0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 4, 4, 32)     18432       conv4_block2_1_leakyRelu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_concat (Concatenat (None, 4, 4, 338)    0           conv4_block1_concat[0][0]        \n",
      "                                                                 conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 4, 4, 338)    1352        conv4_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_27 (LeakyReLU)      (None, 4, 4, 338)    0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 4, 4, 64)     21632       leaky_re_lu_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 4, 4, 64)     256         conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_leakyRelu (Leaky (None, 4, 4, 64)     0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 4, 4, 32)     18432       conv4_block3_1_leakyRelu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_concat (Concatenat (None, 4, 4, 370)    0           conv4_block2_concat[0][0]        \n",
      "                                                                 conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 4, 4, 370)    1480        conv4_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_28 (LeakyReLU)      (None, 4, 4, 370)    0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 4, 4, 64)     23680       leaky_re_lu_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 4, 4, 64)     256         conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_leakyRelu (Leaky (None, 4, 4, 64)     0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 4, 4, 32)     18432       conv4_block4_1_leakyRelu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_concat (Concatenat (None, 4, 4, 402)    0           conv4_block3_concat[0][0]        \n",
      "                                                                 conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 4, 4, 402)    1608        conv4_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_29 (LeakyReLU)      (None, 4, 4, 402)    0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 4, 4, 64)     25728       leaky_re_lu_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 4, 4, 64)     256         conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_leakyRelu (Leaky (None, 4, 4, 64)     0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 4, 4, 32)     18432       conv4_block5_1_leakyRelu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_concat (Concatenat (None, 4, 4, 434)    0           conv4_block4_concat[0][0]        \n",
      "                                                                 conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 4, 4, 434)    1736        conv4_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_30 (LeakyReLU)      (None, 4, 4, 434)    0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 4, 4, 64)     27776       leaky_re_lu_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 4, 4, 64)     256         conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_leakyRelu (Leaky (None, 4, 4, 64)     0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 4, 4, 32)     18432       conv4_block6_1_leakyRelu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_concat (Concatenat (None, 4, 4, 466)    0           conv4_block5_concat[0][0]        \n",
      "                                                                 conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 4, 4, 466)    1864        conv4_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_31 (LeakyReLU)      (None, 4, 4, 466)    0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_conv (Conv2D)    (None, 4, 4, 64)     29824       leaky_re_lu_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 4, 4, 64)     256         conv4_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_leakyRelu (Leaky (None, 4, 4, 64)     0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_conv (Conv2D)    (None, 4, 4, 32)     18432       conv4_block7_1_leakyRelu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_concat (Concatenat (None, 4, 4, 498)    0           conv4_block6_concat[0][0]        \n",
      "                                                                 conv4_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 4, 4, 498)    1992        conv4_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_32 (LeakyReLU)      (None, 4, 4, 498)    0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_conv (Conv2D)    (None, 4, 4, 64)     31872       leaky_re_lu_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 4, 4, 64)     256         conv4_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_leakyRelu (Leaky (None, 4, 4, 64)     0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_conv (Conv2D)    (None, 4, 4, 32)     18432       conv4_block8_1_leakyRelu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_concat (Concatenat (None, 4, 4, 530)    0           conv4_block7_concat[0][0]        \n",
      "                                                                 conv4_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 4, 4, 530)    2120        conv4_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_33 (LeakyReLU)      (None, 4, 4, 530)    0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_conv (Conv2D)    (None, 4, 4, 64)     33920       leaky_re_lu_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 4, 4, 64)     256         conv4_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_leakyRelu (Leaky (None, 4, 4, 64)     0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_conv (Conv2D)    (None, 4, 4, 32)     18432       conv4_block9_1_leakyRelu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_concat (Concatenat (None, 4, 4, 562)    0           conv4_block8_concat[0][0]        \n",
      "                                                                 conv4_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 4, 4, 562)    2248        conv4_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_34 (LeakyReLU)      (None, 4, 4, 562)    0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_conv (Conv2D)   (None, 4, 4, 64)     35968       leaky_re_lu_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 4, 4, 64)     256         conv4_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_leakyRelu (Leak (None, 4, 4, 64)     0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_conv (Conv2D)   (None, 4, 4, 32)     18432       conv4_block10_1_leakyRelu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_concat (Concatena (None, 4, 4, 594)    0           conv4_block9_concat[0][0]        \n",
      "                                                                 conv4_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bn (BatchNormalization)         (None, 4, 4, 594)    2376        conv4_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "leakyRelu (LeakyReLU)           (None, 4, 4, 594)    0           bn[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 594)          0           leakyRelu[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "fc (Dense)                      (None, 10)           5950        avg_pool[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,541,742\n",
      "Trainable params: 1,514,186\n",
      "Non-trainable params: 27,556\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# implement the code of your DenseNet-73 model here.\n",
    "model_73 = my_model((4, 8, 12, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"densenet_73\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "img (InputLayer)                [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 32, 16)   448         img[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_35 (LeakyReLU)      (None, 32, 32, 16)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 32, 32, 16)   64          leaky_re_lu_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_36 (LeakyReLU)      (None, 32, 32, 16)   0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1_block1_1_conv (Conv2D)    (None, 32, 32, 64)   1024        leaky_re_lu_36[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 32, 32, 64)   256         conv1_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1_block1_1_leakyRelu (Leaky (None, 32, 32, 64)   0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1_block1_2_conv (Conv2D)    (None, 32, 32, 32)   18432       conv1_block1_1_leakyRelu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv1_block1_concat (Concatenat (None, 32, 32, 48)   0           leaky_re_lu_35[0][0]             \n",
      "                                                                 conv1_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 32, 32, 48)   192         conv1_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_37 (LeakyReLU)      (None, 32, 32, 48)   0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1_block2_1_conv (Conv2D)    (None, 32, 32, 64)   3072        leaky_re_lu_37[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 32, 32, 64)   256         conv1_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1_block2_1_leakyRelu (Leaky (None, 32, 32, 64)   0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1_block2_2_conv (Conv2D)    (None, 32, 32, 32)   18432       conv1_block2_1_leakyRelu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv1_block2_concat (Concatenat (None, 32, 32, 80)   0           conv1_block1_concat[0][0]        \n",
      "                                                                 conv1_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 32, 32, 80)   320         conv1_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_38 (LeakyReLU)      (None, 32, 32, 80)   0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1_block3_1_conv (Conv2D)    (None, 32, 32, 64)   5120        leaky_re_lu_38[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 32, 32, 64)   256         conv1_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1_block3_1_leakyRelu (Leaky (None, 32, 32, 64)   0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1_block3_2_conv (Conv2D)    (None, 32, 32, 32)   18432       conv1_block3_1_leakyRelu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv1_block3_concat (Concatenat (None, 32, 32, 112)  0           conv1_block2_concat[0][0]        \n",
      "                                                                 conv1_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 32, 32, 112)  448         conv1_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_39 (LeakyReLU)      (None, 32, 32, 112)  0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1_block4_1_conv (Conv2D)    (None, 32, 32, 64)   7168        leaky_re_lu_39[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 32, 32, 64)   256         conv1_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1_block4_1_leakyRelu (Leaky (None, 32, 32, 64)   0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1_block4_2_conv (Conv2D)    (None, 32, 32, 32)   18432       conv1_block4_1_leakyRelu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv1_block4_concat (Concatenat (None, 32, 32, 144)  0           conv1_block3_concat[0][0]        \n",
      "                                                                 conv1_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool1_bn (BatchNormalization)   (None, 32, 32, 144)  576         conv1_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool1_leakyRelu (LeakyReLU)     (None, 32, 32, 144)  0           pool1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_conv (Conv2D)             (None, 32, 32, 72)   10368       pool1_leakyRelu[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (AveragePooling2D)   (None, 16, 16, 72)   0           pool1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 16, 16, 72)   288         pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_40 (LeakyReLU)      (None, 16, 16, 72)   0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 16, 16, 64)   4608        leaky_re_lu_40[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 16, 16, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_leakyRelu (Leaky (None, 16, 16, 64)   0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 16, 16, 32)   18432       conv2_block1_1_leakyRelu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_concat (Concatenat (None, 16, 16, 104)  0           pool1_pool[0][0]                 \n",
      "                                                                 conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 16, 16, 104)  416         conv2_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_41 (LeakyReLU)      (None, 16, 16, 104)  0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 16, 16, 64)   6656        leaky_re_lu_41[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 16, 16, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_leakyRelu (Leaky (None, 16, 16, 64)   0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 16, 16, 32)   18432       conv2_block2_1_leakyRelu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_concat (Concatenat (None, 16, 16, 136)  0           conv2_block1_concat[0][0]        \n",
      "                                                                 conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 16, 16, 136)  544         conv2_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_42 (LeakyReLU)      (None, 16, 16, 136)  0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 16, 16, 64)   8704        leaky_re_lu_42[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 16, 16, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_leakyRelu (Leaky (None, 16, 16, 64)   0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 16, 16, 32)   18432       conv2_block3_1_leakyRelu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_concat (Concatenat (None, 16, 16, 168)  0           conv2_block2_concat[0][0]        \n",
      "                                                                 conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 16, 16, 168)  672         conv2_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_43 (LeakyReLU)      (None, 16, 16, 168)  0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_conv (Conv2D)    (None, 16, 16, 64)   10752       leaky_re_lu_43[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 16, 16, 64)   256         conv2_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_leakyRelu (Leaky (None, 16, 16, 64)   0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_2_conv (Conv2D)    (None, 16, 16, 32)   18432       conv2_block4_1_leakyRelu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_concat (Concatenat (None, 16, 16, 200)  0           conv2_block3_concat[0][0]        \n",
      "                                                                 conv2_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 16, 16, 200)  800         conv2_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_44 (LeakyReLU)      (None, 16, 16, 200)  0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_conv (Conv2D)    (None, 16, 16, 64)   12800       leaky_re_lu_44[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 16, 16, 64)   256         conv2_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_leakyRelu (Leaky (None, 16, 16, 64)   0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_2_conv (Conv2D)    (None, 16, 16, 32)   18432       conv2_block5_1_leakyRelu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_concat (Concatenat (None, 16, 16, 232)  0           conv2_block4_concat[0][0]        \n",
      "                                                                 conv2_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 16, 16, 232)  928         conv2_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_45 (LeakyReLU)      (None, 16, 16, 232)  0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_conv (Conv2D)    (None, 16, 16, 64)   14848       leaky_re_lu_45[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 16, 16, 64)   256         conv2_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_leakyRelu (Leaky (None, 16, 16, 64)   0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_2_conv (Conv2D)    (None, 16, 16, 32)   18432       conv2_block6_1_leakyRelu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_concat (Concatenat (None, 16, 16, 264)  0           conv2_block5_concat[0][0]        \n",
      "                                                                 conv2_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 16, 16, 264)  1056        conv2_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_46 (LeakyReLU)      (None, 16, 16, 264)  0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block7_1_conv (Conv2D)    (None, 16, 16, 64)   16896       leaky_re_lu_46[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 16, 16, 64)   256         conv2_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block7_1_leakyRelu (Leaky (None, 16, 16, 64)   0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block7_2_conv (Conv2D)    (None, 16, 16, 32)   18432       conv2_block7_1_leakyRelu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block7_concat (Concatenat (None, 16, 16, 296)  0           conv2_block6_concat[0][0]        \n",
      "                                                                 conv2_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 16, 16, 296)  1184        conv2_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_47 (LeakyReLU)      (None, 16, 16, 296)  0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block8_1_conv (Conv2D)    (None, 16, 16, 64)   18944       leaky_re_lu_47[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 16, 16, 64)   256         conv2_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block8_1_leakyRelu (Leaky (None, 16, 16, 64)   0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block8_2_conv (Conv2D)    (None, 16, 16, 32)   18432       conv2_block8_1_leakyRelu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block8_concat (Concatenat (None, 16, 16, 328)  0           conv2_block7_concat[0][0]        \n",
      "                                                                 conv2_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_bn (BatchNormalization)   (None, 16, 16, 328)  1312        conv2_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_leakyRelu (LeakyReLU)     (None, 16, 16, 328)  0           pool2_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool2_conv (Conv2D)             (None, 16, 16, 164)  53792       pool2_leakyRelu[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "pool2_pool (AveragePooling2D)   (None, 8, 8, 164)    0           pool2_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 8, 8, 164)    656         pool2_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_48 (LeakyReLU)      (None, 8, 8, 164)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 8, 8, 64)     10496       leaky_re_lu_48[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 8, 8, 64)     256         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_leakyRelu (Leaky (None, 8, 8, 64)     0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 8, 8, 32)     18432       conv3_block1_1_leakyRelu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_concat (Concatenat (None, 8, 8, 196)    0           pool2_pool[0][0]                 \n",
      "                                                                 conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 8, 8, 196)    784         conv3_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_49 (LeakyReLU)      (None, 8, 8, 196)    0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 8, 8, 64)     12544       leaky_re_lu_49[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 8, 8, 64)     256         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_leakyRelu (Leaky (None, 8, 8, 64)     0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 8, 8, 32)     18432       conv3_block2_1_leakyRelu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_concat (Concatenat (None, 8, 8, 228)    0           conv3_block1_concat[0][0]        \n",
      "                                                                 conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 8, 8, 228)    912         conv3_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_50 (LeakyReLU)      (None, 8, 8, 228)    0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 8, 8, 64)     14592       leaky_re_lu_50[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 8, 8, 64)     256         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_leakyRelu (Leaky (None, 8, 8, 64)     0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 8, 8, 32)     18432       conv3_block3_1_leakyRelu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_concat (Concatenat (None, 8, 8, 260)    0           conv3_block2_concat[0][0]        \n",
      "                                                                 conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 8, 8, 260)    1040        conv3_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_51 (LeakyReLU)      (None, 8, 8, 260)    0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 8, 8, 64)     16640       leaky_re_lu_51[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 8, 8, 64)     256         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_leakyRelu (Leaky (None, 8, 8, 64)     0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 8, 8, 32)     18432       conv3_block4_1_leakyRelu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_concat (Concatenat (None, 8, 8, 292)    0           conv3_block3_concat[0][0]        \n",
      "                                                                 conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 8, 8, 292)    1168        conv3_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_52 (LeakyReLU)      (None, 8, 8, 292)    0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_conv (Conv2D)    (None, 8, 8, 64)     18688       leaky_re_lu_52[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 8, 8, 64)     256         conv3_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_leakyRelu (Leaky (None, 8, 8, 64)     0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_2_conv (Conv2D)    (None, 8, 8, 32)     18432       conv3_block5_1_leakyRelu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_concat (Concatenat (None, 8, 8, 324)    0           conv3_block4_concat[0][0]        \n",
      "                                                                 conv3_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 8, 8, 324)    1296        conv3_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_53 (LeakyReLU)      (None, 8, 8, 324)    0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_conv (Conv2D)    (None, 8, 8, 64)     20736       leaky_re_lu_53[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 8, 8, 64)     256         conv3_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_leakyRelu (Leaky (None, 8, 8, 64)     0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_2_conv (Conv2D)    (None, 8, 8, 32)     18432       conv3_block6_1_leakyRelu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_concat (Concatenat (None, 8, 8, 356)    0           conv3_block5_concat[0][0]        \n",
      "                                                                 conv3_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 8, 8, 356)    1424        conv3_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_54 (LeakyReLU)      (None, 8, 8, 356)    0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_conv (Conv2D)    (None, 8, 8, 64)     22784       leaky_re_lu_54[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 8, 8, 64)     256         conv3_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_leakyRelu (Leaky (None, 8, 8, 64)     0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_2_conv (Conv2D)    (None, 8, 8, 32)     18432       conv3_block7_1_leakyRelu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_concat (Concatenat (None, 8, 8, 388)    0           conv3_block6_concat[0][0]        \n",
      "                                                                 conv3_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 8, 8, 388)    1552        conv3_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_55 (LeakyReLU)      (None, 8, 8, 388)    0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_conv (Conv2D)    (None, 8, 8, 64)     24832       leaky_re_lu_55[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 8, 8, 64)     256         conv3_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_leakyRelu (Leaky (None, 8, 8, 64)     0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_2_conv (Conv2D)    (None, 8, 8, 32)     18432       conv3_block8_1_leakyRelu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_concat (Concatenat (None, 8, 8, 420)    0           conv3_block7_concat[0][0]        \n",
      "                                                                 conv3_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 8, 8, 420)    1680        conv3_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_56 (LeakyReLU)      (None, 8, 8, 420)    0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_conv (Conv2D)    (None, 8, 8, 64)     26880       leaky_re_lu_56[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 8, 8, 64)     256         conv3_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_leakyRelu (Leaky (None, 8, 8, 64)     0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_2_conv (Conv2D)    (None, 8, 8, 32)     18432       conv3_block9_1_leakyRelu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_concat (Concatenat (None, 8, 8, 452)    0           conv3_block8_concat[0][0]        \n",
      "                                                                 conv3_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 8, 8, 452)    1808        conv3_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_57 (LeakyReLU)      (None, 8, 8, 452)    0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_conv (Conv2D)   (None, 8, 8, 64)     28928       leaky_re_lu_57[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 8, 8, 64)     256         conv3_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_leakyRelu (Leak (None, 8, 8, 64)     0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_2_conv (Conv2D)   (None, 8, 8, 32)     18432       conv3_block10_1_leakyRelu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_concat (Concatena (None, 8, 8, 484)    0           conv3_block9_concat[0][0]        \n",
      "                                                                 conv3_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 8, 8, 484)    1936        conv3_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_58 (LeakyReLU)      (None, 8, 8, 484)    0           batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_conv (Conv2D)   (None, 8, 8, 64)     30976       leaky_re_lu_58[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 8, 8, 64)     256         conv3_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_leakyRelu (Leak (None, 8, 8, 64)     0           batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_2_conv (Conv2D)   (None, 8, 8, 32)     18432       conv3_block11_1_leakyRelu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_concat (Concatena (None, 8, 8, 516)    0           conv3_block10_concat[0][0]       \n",
      "                                                                 conv3_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 8, 8, 516)    2064        conv3_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_59 (LeakyReLU)      (None, 8, 8, 516)    0           batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_conv (Conv2D)   (None, 8, 8, 64)     33024       leaky_re_lu_59[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 8, 8, 64)     256         conv3_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_leakyRelu (Leak (None, 8, 8, 64)     0           batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_2_conv (Conv2D)   (None, 8, 8, 32)     18432       conv3_block12_1_leakyRelu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_concat (Concatena (None, 8, 8, 548)    0           conv3_block11_concat[0][0]       \n",
      "                                                                 conv3_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 8, 8, 548)    2192        conv3_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_60 (LeakyReLU)      (None, 8, 8, 548)    0           batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block13_1_conv (Conv2D)   (None, 8, 8, 64)     35072       leaky_re_lu_60[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, 8, 8, 64)     256         conv3_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block13_1_leakyRelu (Leak (None, 8, 8, 64)     0           batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block13_2_conv (Conv2D)   (None, 8, 8, 32)     18432       conv3_block13_1_leakyRelu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block13_concat (Concatena (None, 8, 8, 580)    0           conv3_block12_concat[0][0]       \n",
      "                                                                 conv3_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, 8, 8, 580)    2320        conv3_block13_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_61 (LeakyReLU)      (None, 8, 8, 580)    0           batch_normalization_118[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block14_1_conv (Conv2D)   (None, 8, 8, 64)     37120       leaky_re_lu_61[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, 8, 8, 64)     256         conv3_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block14_1_leakyRelu (Leak (None, 8, 8, 64)     0           batch_normalization_119[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block14_2_conv (Conv2D)   (None, 8, 8, 32)     18432       conv3_block14_1_leakyRelu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block14_concat (Concatena (None, 8, 8, 612)    0           conv3_block13_concat[0][0]       \n",
      "                                                                 conv3_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, 8, 8, 612)    2448        conv3_block14_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_62 (LeakyReLU)      (None, 8, 8, 612)    0           batch_normalization_120[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block15_1_conv (Conv2D)   (None, 8, 8, 64)     39168       leaky_re_lu_62[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchN (None, 8, 8, 64)     256         conv3_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block15_1_leakyRelu (Leak (None, 8, 8, 64)     0           batch_normalization_121[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block15_2_conv (Conv2D)   (None, 8, 8, 32)     18432       conv3_block15_1_leakyRelu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block15_concat (Concatena (None, 8, 8, 644)    0           conv3_block14_concat[0][0]       \n",
      "                                                                 conv3_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchN (None, 8, 8, 644)    2576        conv3_block15_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_63 (LeakyReLU)      (None, 8, 8, 644)    0           batch_normalization_122[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block16_1_conv (Conv2D)   (None, 8, 8, 64)     41216       leaky_re_lu_63[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchN (None, 8, 8, 64)     256         conv3_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block16_1_leakyRelu (Leak (None, 8, 8, 64)     0           batch_normalization_123[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block16_2_conv (Conv2D)   (None, 8, 8, 32)     18432       conv3_block16_1_leakyRelu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block16_concat (Concatena (None, 8, 8, 676)    0           conv3_block15_concat[0][0]       \n",
      "                                                                 conv3_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_bn (BatchNormalization)   (None, 8, 8, 676)    2704        conv3_block16_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_leakyRelu (LeakyReLU)     (None, 8, 8, 676)    0           pool3_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool3_conv (Conv2D)             (None, 8, 8, 338)    228488      pool3_leakyRelu[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "pool3_pool (AveragePooling2D)   (None, 4, 4, 338)    0           pool3_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchN (None, 4, 4, 338)    1352        pool3_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_64 (LeakyReLU)      (None, 4, 4, 338)    0           batch_normalization_124[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 4, 4, 64)     21632       leaky_re_lu_64[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchN (None, 4, 4, 64)     256         conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_leakyRelu (Leaky (None, 4, 4, 64)     0           batch_normalization_125[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 4, 4, 32)     18432       conv4_block1_1_leakyRelu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_concat (Concatenat (None, 4, 4, 370)    0           pool3_pool[0][0]                 \n",
      "                                                                 conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchN (None, 4, 4, 370)    1480        conv4_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_65 (LeakyReLU)      (None, 4, 4, 370)    0           batch_normalization_126[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 4, 4, 64)     23680       leaky_re_lu_65[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchN (None, 4, 4, 64)     256         conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_leakyRelu (Leaky (None, 4, 4, 64)     0           batch_normalization_127[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 4, 4, 32)     18432       conv4_block2_1_leakyRelu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_concat (Concatenat (None, 4, 4, 402)    0           conv4_block1_concat[0][0]        \n",
      "                                                                 conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchN (None, 4, 4, 402)    1608        conv4_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_66 (LeakyReLU)      (None, 4, 4, 402)    0           batch_normalization_128[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 4, 4, 64)     25728       leaky_re_lu_66[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchN (None, 4, 4, 64)     256         conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_leakyRelu (Leaky (None, 4, 4, 64)     0           batch_normalization_129[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 4, 4, 32)     18432       conv4_block3_1_leakyRelu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_concat (Concatenat (None, 4, 4, 434)    0           conv4_block2_concat[0][0]        \n",
      "                                                                 conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchN (None, 4, 4, 434)    1736        conv4_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_67 (LeakyReLU)      (None, 4, 4, 434)    0           batch_normalization_130[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 4, 4, 64)     27776       leaky_re_lu_67[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchN (None, 4, 4, 64)     256         conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_leakyRelu (Leaky (None, 4, 4, 64)     0           batch_normalization_131[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 4, 4, 32)     18432       conv4_block4_1_leakyRelu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_concat (Concatenat (None, 4, 4, 466)    0           conv4_block3_concat[0][0]        \n",
      "                                                                 conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchN (None, 4, 4, 466)    1864        conv4_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_68 (LeakyReLU)      (None, 4, 4, 466)    0           batch_normalization_132[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 4, 4, 64)     29824       leaky_re_lu_68[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchN (None, 4, 4, 64)     256         conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_leakyRelu (Leaky (None, 4, 4, 64)     0           batch_normalization_133[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 4, 4, 32)     18432       conv4_block5_1_leakyRelu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_concat (Concatenat (None, 4, 4, 498)    0           conv4_block4_concat[0][0]        \n",
      "                                                                 conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_134 (BatchN (None, 4, 4, 498)    1992        conv4_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_69 (LeakyReLU)      (None, 4, 4, 498)    0           batch_normalization_134[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 4, 4, 64)     31872       leaky_re_lu_69[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_135 (BatchN (None, 4, 4, 64)     256         conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_leakyRelu (Leaky (None, 4, 4, 64)     0           batch_normalization_135[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 4, 4, 32)     18432       conv4_block6_1_leakyRelu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_concat (Concatenat (None, 4, 4, 530)    0           conv4_block5_concat[0][0]        \n",
      "                                                                 conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_136 (BatchN (None, 4, 4, 530)    2120        conv4_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_70 (LeakyReLU)      (None, 4, 4, 530)    0           batch_normalization_136[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_conv (Conv2D)    (None, 4, 4, 64)     33920       leaky_re_lu_70[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_137 (BatchN (None, 4, 4, 64)     256         conv4_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_leakyRelu (Leaky (None, 4, 4, 64)     0           batch_normalization_137[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_conv (Conv2D)    (None, 4, 4, 32)     18432       conv4_block7_1_leakyRelu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_concat (Concatenat (None, 4, 4, 562)    0           conv4_block6_concat[0][0]        \n",
      "                                                                 conv4_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_138 (BatchN (None, 4, 4, 562)    2248        conv4_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_71 (LeakyReLU)      (None, 4, 4, 562)    0           batch_normalization_138[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_conv (Conv2D)    (None, 4, 4, 64)     35968       leaky_re_lu_71[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_139 (BatchN (None, 4, 4, 64)     256         conv4_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_leakyRelu (Leaky (None, 4, 4, 64)     0           batch_normalization_139[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_conv (Conv2D)    (None, 4, 4, 32)     18432       conv4_block8_1_leakyRelu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_concat (Concatenat (None, 4, 4, 594)    0           conv4_block7_concat[0][0]        \n",
      "                                                                 conv4_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_140 (BatchN (None, 4, 4, 594)    2376        conv4_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_72 (LeakyReLU)      (None, 4, 4, 594)    0           batch_normalization_140[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_conv (Conv2D)    (None, 4, 4, 64)     38016       leaky_re_lu_72[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_141 (BatchN (None, 4, 4, 64)     256         conv4_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_leakyRelu (Leaky (None, 4, 4, 64)     0           batch_normalization_141[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_conv (Conv2D)    (None, 4, 4, 32)     18432       conv4_block9_1_leakyRelu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_concat (Concatenat (None, 4, 4, 626)    0           conv4_block8_concat[0][0]        \n",
      "                                                                 conv4_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_142 (BatchN (None, 4, 4, 626)    2504        conv4_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_73 (LeakyReLU)      (None, 4, 4, 626)    0           batch_normalization_142[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_conv (Conv2D)   (None, 4, 4, 64)     40064       leaky_re_lu_73[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_143 (BatchN (None, 4, 4, 64)     256         conv4_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_leakyRelu (Leak (None, 4, 4, 64)     0           batch_normalization_143[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_conv (Conv2D)   (None, 4, 4, 32)     18432       conv4_block10_1_leakyRelu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_concat (Concatena (None, 4, 4, 658)    0           conv4_block9_concat[0][0]        \n",
      "                                                                 conv4_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_144 (BatchN (None, 4, 4, 658)    2632        conv4_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_74 (LeakyReLU)      (None, 4, 4, 658)    0           batch_normalization_144[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_conv (Conv2D)   (None, 4, 4, 64)     42112       leaky_re_lu_74[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_145 (BatchN (None, 4, 4, 64)     256         conv4_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_leakyRelu (Leak (None, 4, 4, 64)     0           batch_normalization_145[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_conv (Conv2D)   (None, 4, 4, 32)     18432       conv4_block11_1_leakyRelu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_concat (Concatena (None, 4, 4, 690)    0           conv4_block10_concat[0][0]       \n",
      "                                                                 conv4_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_146 (BatchN (None, 4, 4, 690)    2760        conv4_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_75 (LeakyReLU)      (None, 4, 4, 690)    0           batch_normalization_146[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_conv (Conv2D)   (None, 4, 4, 64)     44160       leaky_re_lu_75[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_147 (BatchN (None, 4, 4, 64)     256         conv4_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_leakyRelu (Leak (None, 4, 4, 64)     0           batch_normalization_147[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_conv (Conv2D)   (None, 4, 4, 32)     18432       conv4_block12_1_leakyRelu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_concat (Concatena (None, 4, 4, 722)    0           conv4_block11_concat[0][0]       \n",
      "                                                                 conv4_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_148 (BatchN (None, 4, 4, 722)    2888        conv4_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_76 (LeakyReLU)      (None, 4, 4, 722)    0           batch_normalization_148[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_conv (Conv2D)   (None, 4, 4, 64)     46208       leaky_re_lu_76[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_149 (BatchN (None, 4, 4, 64)     256         conv4_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_leakyRelu (Leak (None, 4, 4, 64)     0           batch_normalization_149[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_conv (Conv2D)   (None, 4, 4, 32)     18432       conv4_block13_1_leakyRelu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_concat (Concatena (None, 4, 4, 754)    0           conv4_block12_concat[0][0]       \n",
      "                                                                 conv4_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_150 (BatchN (None, 4, 4, 754)    3016        conv4_block13_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_77 (LeakyReLU)      (None, 4, 4, 754)    0           batch_normalization_150[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_conv (Conv2D)   (None, 4, 4, 64)     48256       leaky_re_lu_77[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_151 (BatchN (None, 4, 4, 64)     256         conv4_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_leakyRelu (Leak (None, 4, 4, 64)     0           batch_normalization_151[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_conv (Conv2D)   (None, 4, 4, 32)     18432       conv4_block14_1_leakyRelu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_concat (Concatena (None, 4, 4, 786)    0           conv4_block13_concat[0][0]       \n",
      "                                                                 conv4_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_152 (BatchN (None, 4, 4, 786)    3144        conv4_block14_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_78 (LeakyReLU)      (None, 4, 4, 786)    0           batch_normalization_152[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_conv (Conv2D)   (None, 4, 4, 64)     50304       leaky_re_lu_78[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_153 (BatchN (None, 4, 4, 64)     256         conv4_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_leakyRelu (Leak (None, 4, 4, 64)     0           batch_normalization_153[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_conv (Conv2D)   (None, 4, 4, 32)     18432       conv4_block15_1_leakyRelu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_concat (Concatena (None, 4, 4, 818)    0           conv4_block14_concat[0][0]       \n",
      "                                                                 conv4_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_154 (BatchN (None, 4, 4, 818)    3272        conv4_block15_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_79 (LeakyReLU)      (None, 4, 4, 818)    0           batch_normalization_154[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_conv (Conv2D)   (None, 4, 4, 64)     52352       leaky_re_lu_79[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_155 (BatchN (None, 4, 4, 64)     256         conv4_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_leakyRelu (Leak (None, 4, 4, 64)     0           batch_normalization_155[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_conv (Conv2D)   (None, 4, 4, 32)     18432       conv4_block16_1_leakyRelu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_concat (Concatena (None, 4, 4, 850)    0           conv4_block15_concat[0][0]       \n",
      "                                                                 conv4_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bn (BatchNormalization)         (None, 4, 4, 850)    3400        conv4_block16_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "leakyRelu (LeakyReLU)           (None, 4, 4, 850)    0           bn[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 850)          0           leakyRelu[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "fc (Dense)                      (None, 10)           8510        avg_pool[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 2,317,790\n",
      "Trainable params: 2,273,282\n",
      "Non-trainable params: 44,508\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# implement the code of your DenseNet-93 model here.\n",
    "model_93 = my_model((4, 8, 16, 16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Train and evaluate your models. (25 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Train your models. (20 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-03 10:25:17.893283: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-11-03 10:25:17.894199: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2400085000 Hz\n",
      "2021-11-03 10:25:23.620459: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2021-11-03 10:25:23.822211: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 40s 64ms/step - loss: 1.4684 - accuracy: 0.4657\n",
      "epoch: 2\n",
      "500/500 [==============================] - 32s 64ms/step - loss: 0.7418 - accuracy: 0.7365\n",
      "epoch: 3\n",
      "500/500 [==============================] - 32s 64ms/step - loss: 0.5789 - accuracy: 0.7983\n",
      "epoch: 4\n",
      "500/500 [==============================] - 32s 64ms/step - loss: 0.4867 - accuracy: 0.8298\n",
      "epoch: 5\n",
      "500/500 [==============================] - 32s 64ms/step - loss: 0.4173 - accuracy: 0.8550\n",
      "epoch: 6\n",
      "500/500 [==============================] - 32s 64ms/step - loss: 0.3598 - accuracy: 0.8753\n",
      "epoch: 7\n",
      "500/500 [==============================] - 32s 63ms/step - loss: 0.3144 - accuracy: 0.8908\n",
      "epoch: 8\n",
      "500/500 [==============================] - 32s 63ms/step - loss: 0.2696 - accuracy: 0.9058\n",
      "epoch: 9\n",
      "500/500 [==============================] - 31s 63ms/step - loss: 0.2334 - accuracy: 0.9195\n",
      "epoch: 10\n",
      "500/500 [==============================] - 32s 64ms/step - loss: 0.2024 - accuracy: 0.9292\n",
      "epoch: 11\n",
      "500/500 [==============================] - 32s 63ms/step - loss: 0.1702 - accuracy: 0.9393\n",
      "epoch: 12\n",
      "500/500 [==============================] - 31s 63ms/step - loss: 0.1503 - accuracy: 0.9474\n",
      "epoch: 13\n",
      "500/500 [==============================] - 31s 63ms/step - loss: 0.1357 - accuracy: 0.9521\n",
      "epoch: 14\n",
      "500/500 [==============================] - 31s 63ms/step - loss: 0.1158 - accuracy: 0.9589\n",
      "epoch: 15\n",
      "500/500 [==============================] - 32s 63ms/step - loss: 0.1011 - accuracy: 0.9646\n",
      "epoch: 16\n",
      "500/500 [==============================] - 31s 63ms/step - loss: 0.0930 - accuracy: 0.9680\n",
      "epoch: 17\n",
      "500/500 [==============================] - 31s 62ms/step - loss: 0.0848 - accuracy: 0.9703\n",
      "epoch: 18\n",
      "500/500 [==============================] - 31s 62ms/step - loss: 0.0775 - accuracy: 0.9718\n",
      "epoch: 19\n",
      "500/500 [==============================] - 31s 63ms/step - loss: 0.0645 - accuracy: 0.9769\n",
      "epoch: 20\n",
      "500/500 [==============================] - 31s 62ms/step - loss: 0.0667 - accuracy: 0.9765\n",
      "epoch: 21\n",
      "500/500 [==============================] - 31s 63ms/step - loss: 0.0663 - accuracy: 0.9760\n",
      "epoch: 22\n",
      "500/500 [==============================] - 31s 62ms/step - loss: 0.0541 - accuracy: 0.9808\n",
      "epoch: 23\n",
      "500/500 [==============================] - 31s 62ms/step - loss: 0.0615 - accuracy: 0.9778\n",
      "epoch: 24\n",
      "500/500 [==============================] - 31s 63ms/step - loss: 0.0518 - accuracy: 0.9825\n",
      "epoch: 25\n",
      "500/500 [==============================] - 31s 63ms/step - loss: 0.0435 - accuracy: 0.9852\n",
      "epoch: 26\n",
      "500/500 [==============================] - 31s 63ms/step - loss: 0.0486 - accuracy: 0.9834\n",
      "epoch: 27\n",
      "500/500 [==============================] - 31s 62ms/step - loss: 0.0454 - accuracy: 0.9844\n",
      "epoch: 28\n",
      "500/500 [==============================] - 31s 63ms/step - loss: 0.0454 - accuracy: 0.9842\n",
      "epoch: 29\n",
      "500/500 [==============================] - 31s 63ms/step - loss: 0.0467 - accuracy: 0.9836\n",
      "epoch: 30\n",
      "500/500 [==============================] - 31s 62ms/step - loss: 0.0369 - accuracy: 0.9871\n",
      "epoch: 31\n",
      "500/500 [==============================] - 31s 63ms/step - loss: 0.0375 - accuracy: 0.9874\n",
      "epoch: 32\n",
      "500/500 [==============================] - 31s 62ms/step - loss: 0.0389 - accuracy: 0.9864\n",
      "epoch: 33\n",
      "500/500 [==============================] - 31s 62ms/step - loss: 0.0314 - accuracy: 0.9892\n",
      "epoch: 34\n",
      "500/500 [==============================] - 31s 62ms/step - loss: 0.0470 - accuracy: 0.9834\n",
      "epoch: 35\n",
      "500/500 [==============================] - 31s 62ms/step - loss: 0.0221 - accuracy: 0.9927\n",
      "epoch: 36\n",
      "500/500 [==============================] - 31s 62ms/step - loss: 0.0370 - accuracy: 0.9868\n",
      "epoch: 37\n",
      "500/500 [==============================] - 31s 62ms/step - loss: 0.0286 - accuracy: 0.9907\n",
      "epoch: 38\n",
      "500/500 [==============================] - 31s 62ms/step - loss: 0.0347 - accuracy: 0.9881\n",
      "epoch: 39\n",
      "500/500 [==============================] - 31s 62ms/step - loss: 0.0278 - accuracy: 0.9906\n",
      "epoch: 40\n",
      "500/500 [==============================] - 31s 62ms/step - loss: 0.0342 - accuracy: 0.9879\n",
      "epoch: 41\n",
      "500/500 [==============================] - 31s 62ms/step - loss: 0.0263 - accuracy: 0.9907\n",
      "epoch: 42\n",
      "500/500 [==============================] - 31s 62ms/step - loss: 0.0240 - accuracy: 0.9919\n",
      "epoch: 43\n",
      "500/500 [==============================] - 31s 62ms/step - loss: 0.0322 - accuracy: 0.9880\n",
      "epoch: 44\n",
      "500/500 [==============================] - 31s 61ms/step - loss: 0.0206 - accuracy: 0.9930\n",
      "epoch: 45\n",
      "500/500 [==============================] - 31s 63ms/step - loss: 0.0279 - accuracy: 0.9908\n",
      "epoch: 46\n",
      "500/500 [==============================] - 31s 62ms/step - loss: 0.0271 - accuracy: 0.9906\n",
      "epoch: 47\n",
      "500/500 [==============================] - 31s 63ms/step - loss: 0.0207 - accuracy: 0.9929\n",
      "epoch: 48\n",
      "500/500 [==============================] - 31s 62ms/step - loss: 0.0297 - accuracy: 0.9897\n",
      "epoch: 49\n",
      "500/500 [==============================] - 31s 62ms/step - loss: 0.0189 - accuracy: 0.9934\n",
      "epoch: 50\n",
      "500/500 [==============================] - 31s 62ms/step - loss: 0.0250 - accuracy: 0.9917\n",
      "epoch: 51\n",
      "500/500 [==============================] - 31s 61ms/step - loss: 0.0215 - accuracy: 0.9923\n",
      "epoch: 52\n",
      "500/500 [==============================] - 31s 62ms/step - loss: 0.0221 - accuracy: 0.9924\n",
      "epoch: 53\n",
      "500/500 [==============================] - 31s 62ms/step - loss: 0.0198 - accuracy: 0.9930\n",
      "epoch: 54\n",
      "500/500 [==============================] - 31s 61ms/step - loss: 0.0225 - accuracy: 0.9922\n",
      "epoch: 55\n",
      "500/500 [==============================] - 31s 63ms/step - loss: 0.0214 - accuracy: 0.9927\n",
      "epoch: 56\n",
      "500/500 [==============================] - 31s 62ms/step - loss: 0.0167 - accuracy: 0.9939\n",
      "epoch: 57\n",
      "500/500 [==============================] - 31s 62ms/step - loss: 0.0175 - accuracy: 0.9939\n",
      "epoch: 58\n",
      "500/500 [==============================] - 31s 62ms/step - loss: 0.0222 - accuracy: 0.9924\n",
      "epoch: 59\n",
      "500/500 [==============================] - 31s 62ms/step - loss: 0.0212 - accuracy: 0.9925\n",
      "epoch: 60\n",
      "500/500 [==============================] - 31s 62ms/step - loss: 0.0160 - accuracy: 0.9948\n",
      "epoch: 61\n",
      "500/500 [==============================] - 31s 62ms/step - loss: 0.0196 - accuracy: 0.9930\n",
      "epoch: 62\n",
      "500/500 [==============================] - 31s 63ms/step - loss: 0.0164 - accuracy: 0.9945\n",
      "epoch: 63\n",
      "500/500 [==============================] - 31s 62ms/step - loss: 0.0169 - accuracy: 0.9943\n",
      "epoch: 64\n",
      "500/500 [==============================] - 31s 62ms/step - loss: 0.0171 - accuracy: 0.9941\n",
      "epoch: 65\n",
      "500/500 [==============================] - 31s 62ms/step - loss: 0.0194 - accuracy: 0.9940\n",
      "epoch: 66\n",
      "500/500 [==============================] - 31s 63ms/step - loss: 0.0147 - accuracy: 0.9950\n",
      "epoch: 67\n",
      "500/500 [==============================] - 31s 62ms/step - loss: 0.0213 - accuracy: 0.9927\n",
      "epoch: 68\n",
      "500/500 [==============================] - 31s 62ms/step - loss: 0.0179 - accuracy: 0.9938\n",
      "epoch: 69\n",
      "500/500 [==============================] - 31s 62ms/step - loss: 0.0160 - accuracy: 0.9944\n",
      "epoch: 70\n",
      "500/500 [==============================] - 31s 62ms/step - loss: 0.0160 - accuracy: 0.9945\n",
      "epoch: 71\n",
      "500/500 [==============================] - 31s 63ms/step - loss: 0.0136 - accuracy: 0.9955\n",
      "epoch: 72\n",
      "500/500 [==============================] - 31s 62ms/step - loss: 0.0192 - accuracy: 0.9934\n",
      "epoch: 73\n",
      "500/500 [==============================] - 31s 62ms/step - loss: 0.0115 - accuracy: 0.9961\n",
      "epoch: 74\n",
      "500/500 [==============================] - 31s 63ms/step - loss: 0.0178 - accuracy: 0.9938\n",
      "epoch: 75\n",
      "500/500 [==============================] - 31s 61ms/step - loss: 0.0095 - accuracy: 0.9968\n",
      "epoch: 76\n",
      "500/500 [==============================] - 31s 62ms/step - loss: 0.0172 - accuracy: 0.9944\n",
      "epoch: 77\n",
      "500/500 [==============================] - 31s 62ms/step - loss: 0.0190 - accuracy: 0.9936\n",
      "epoch: 78\n",
      "500/500 [==============================] - 31s 62ms/step - loss: 0.0044 - accuracy: 0.9987\n",
      "epoch: 79\n",
      "500/500 [==============================] - 31s 63ms/step - loss: 0.0112 - accuracy: 0.9962\n",
      "epoch: 80\n",
      "500/500 [==============================] - 31s 62ms/step - loss: 0.0222 - accuracy: 0.9924\n",
      "epoch: 81\n",
      "500/500 [==============================] - 31s 61ms/step - loss: 0.0090 - accuracy: 0.9969\n",
      "epoch: 82\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 31s 62ms/step - loss: 0.0185 - accuracy: 0.9941\n",
      "epoch: 83\n",
      "500/500 [==============================] - 31s 63ms/step - loss: 0.0164 - accuracy: 0.9940\n",
      "epoch: 84\n",
      "500/500 [==============================] - 31s 62ms/step - loss: 0.0068 - accuracy: 0.9980\n",
      "epoch: 85\n",
      "500/500 [==============================] - 31s 62ms/step - loss: 0.0163 - accuracy: 0.9944\n",
      "epoch: 86\n",
      "500/500 [==============================] - 31s 62ms/step - loss: 0.0170 - accuracy: 0.9942\n",
      "epoch: 87\n",
      "500/500 [==============================] - 31s 62ms/step - loss: 0.0088 - accuracy: 0.9972\n",
      "epoch: 88\n",
      "500/500 [==============================] - 31s 62ms/step - loss: 0.0086 - accuracy: 0.9971\n",
      "epoch: 89\n",
      "500/500 [==============================] - 31s 62ms/step - loss: 0.0149 - accuracy: 0.9949\n",
      "epoch: 90\n",
      "500/500 [==============================] - 31s 62ms/step - loss: 0.0102 - accuracy: 0.9968\n",
      "epoch: 91\n",
      "500/500 [==============================] - 31s 62ms/step - loss: 0.0069 - accuracy: 0.9976\n",
      "epoch: 92\n",
      "500/500 [==============================] - 31s 62ms/step - loss: 0.0203 - accuracy: 0.9932\n",
      "epoch: 93\n",
      "500/500 [==============================] - 31s 62ms/step - loss: 0.0086 - accuracy: 0.9972\n",
      "epoch: 94\n",
      "500/500 [==============================] - 31s 62ms/step - loss: 0.0114 - accuracy: 0.9962\n",
      "epoch: 95\n",
      "500/500 [==============================] - 31s 62ms/step - loss: 0.0113 - accuracy: 0.9959\n",
      "epoch: 96\n",
      "500/500 [==============================] - 31s 62ms/step - loss: 0.0132 - accuracy: 0.9954\n",
      "epoch: 97\n",
      "500/500 [==============================] - 31s 62ms/step - loss: 0.0122 - accuracy: 0.9960\n",
      "epoch: 98\n",
      "500/500 [==============================] - 31s 62ms/step - loss: 0.0080 - accuracy: 0.9973\n",
      "epoch: 99\n",
      "500/500 [==============================] - 31s 62ms/step - loss: 0.0132 - accuracy: 0.9954\n",
      "epoch: 100\n",
      "500/500 [==============================] - 31s 62ms/step - loss: 0.0147 - accuracy: 0.9953\n",
      "epoch: 1\n",
      "500/500 [==============================] - 44s 74ms/step - loss: 1.4300 - accuracy: 0.4857\n",
      "epoch: 2\n",
      "500/500 [==============================] - 38s 75ms/step - loss: 0.7238 - accuracy: 0.7437\n",
      "epoch: 3\n",
      "500/500 [==============================] - 38s 76ms/step - loss: 0.5646 - accuracy: 0.8022\n",
      "epoch: 4\n",
      "500/500 [==============================] - 37s 75ms/step - loss: 0.4728 - accuracy: 0.8355\n",
      "epoch: 5\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 0.4048 - accuracy: 0.8606\n",
      "epoch: 6\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 0.3431 - accuracy: 0.8810\n",
      "epoch: 7\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 0.3025 - accuracy: 0.8946\n",
      "epoch: 8\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 0.2547 - accuracy: 0.9096\n",
      "epoch: 9\n",
      "500/500 [==============================] - 36s 72ms/step - loss: 0.2293 - accuracy: 0.9198\n",
      "epoch: 10\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 0.1884 - accuracy: 0.9338\n",
      "epoch: 11\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 0.1632 - accuracy: 0.9417\n",
      "epoch: 12\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 0.1391 - accuracy: 0.9519\n",
      "epoch: 13\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 0.1230 - accuracy: 0.9567\n",
      "epoch: 14\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 0.1076 - accuracy: 0.9611\n",
      "epoch: 15\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 0.0968 - accuracy: 0.9656\n",
      "epoch: 16\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 0.0846 - accuracy: 0.9700\n",
      "epoch: 17\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 0.0794 - accuracy: 0.9715\n",
      "epoch: 18\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 0.0734 - accuracy: 0.9731\n",
      "epoch: 19\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 0.0679 - accuracy: 0.9762\n",
      "epoch: 20\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 0.0549 - accuracy: 0.9809\n",
      "epoch: 21\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 0.0676 - accuracy: 0.9766\n",
      "epoch: 22\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 0.0607 - accuracy: 0.9783\n",
      "epoch: 23\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 0.0490 - accuracy: 0.9830\n",
      "epoch: 24\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 0.0474 - accuracy: 0.9835\n",
      "epoch: 25\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 0.0464 - accuracy: 0.9838\n",
      "epoch: 26\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 0.0485 - accuracy: 0.9826\n",
      "epoch: 27\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 0.0402 - accuracy: 0.9858\n",
      "epoch: 28\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 0.0434 - accuracy: 0.9846\n",
      "epoch: 29\n",
      "500/500 [==============================] - 36s 73ms/step - loss: 0.0382 - accuracy: 0.9865\n",
      "epoch: 30\n",
      "500/500 [==============================] - 36s 73ms/step - loss: 0.0340 - accuracy: 0.9883\n",
      "epoch: 31\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 0.0369 - accuracy: 0.9871\n",
      "epoch: 32\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 0.0393 - accuracy: 0.9870\n",
      "epoch: 33\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 0.0321 - accuracy: 0.9891\n",
      "epoch: 34\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 0.0395 - accuracy: 0.9865\n",
      "epoch: 35\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 0.0225 - accuracy: 0.9920\n",
      "epoch: 36\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 0.0411 - accuracy: 0.9856\n",
      "epoch: 37\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 0.0244 - accuracy: 0.9919\n",
      "epoch: 38\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 0.0356 - accuracy: 0.9879\n",
      "epoch: 39\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 0.0239 - accuracy: 0.9920\n",
      "epoch: 40\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 0.0270 - accuracy: 0.9904\n",
      "epoch: 41\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 0.0262 - accuracy: 0.9908\n",
      "epoch: 42\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 0.0342 - accuracy: 0.9885\n",
      "epoch: 43\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 0.0205 - accuracy: 0.9930\n",
      "epoch: 44\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 0.0252 - accuracy: 0.9912\n",
      "epoch: 45\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 0.0239 - accuracy: 0.9919\n",
      "epoch: 46\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 0.0235 - accuracy: 0.9921\n",
      "epoch: 47\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 0.0236 - accuracy: 0.9919\n",
      "epoch: 48\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 0.0249 - accuracy: 0.9908\n",
      "epoch: 49\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 0.0221 - accuracy: 0.9923\n",
      "epoch: 50\n",
      "500/500 [==============================] - 36s 73ms/step - loss: 0.0232 - accuracy: 0.9927\n",
      "epoch: 51\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 0.0208 - accuracy: 0.9928\n",
      "epoch: 52\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 0.0249 - accuracy: 0.9914\n",
      "epoch: 53\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 0.0127 - accuracy: 0.9956\n",
      "epoch: 54\n",
      "500/500 [==============================] - 36s 73ms/step - loss: 0.0179 - accuracy: 0.9938\n",
      "epoch: 55\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 0.0218 - accuracy: 0.9926\n",
      "epoch: 56\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 0.0198 - accuracy: 0.9930\n",
      "epoch: 57\n",
      "500/500 [==============================] - 36s 73ms/step - loss: 0.0165 - accuracy: 0.9947\n",
      "epoch: 58\n",
      "500/500 [==============================] - 36s 73ms/step - loss: 0.0226 - accuracy: 0.9921\n",
      "epoch: 59\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 0.0144 - accuracy: 0.9948\n",
      "epoch: 60\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 0.0178 - accuracy: 0.9938\n",
      "epoch: 61\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 0.0200 - accuracy: 0.9930\n",
      "epoch: 62\n",
      "500/500 [==============================] - 36s 73ms/step - loss: 0.0166 - accuracy: 0.9941\n",
      "epoch: 63\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 37s 73ms/step - loss: 0.0146 - accuracy: 0.9949\n",
      "epoch: 64\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 0.0170 - accuracy: 0.9943\n",
      "epoch: 65\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 0.0196 - accuracy: 0.9931\n",
      "epoch: 66\n",
      "500/500 [==============================] - 36s 73ms/step - loss: 0.0164 - accuracy: 0.9945\n",
      "epoch: 67\n",
      "500/500 [==============================] - 36s 73ms/step - loss: 0.0145 - accuracy: 0.9952\n",
      "epoch: 68\n",
      "500/500 [==============================] - 36s 73ms/step - loss: 0.0173 - accuracy: 0.9940\n",
      "epoch: 69\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 0.0193 - accuracy: 0.9938\n",
      "epoch: 70\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 0.0078 - accuracy: 0.9974\n",
      "epoch: 71\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 0.0180 - accuracy: 0.9938\n",
      "epoch: 72\n",
      "500/500 [==============================] - 36s 73ms/step - loss: 0.0175 - accuracy: 0.9938\n",
      "epoch: 73\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 0.0098 - accuracy: 0.9966\n",
      "epoch: 74\n",
      "500/500 [==============================] - 36s 73ms/step - loss: 0.0169 - accuracy: 0.9941\n",
      "epoch: 75\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 0.0122 - accuracy: 0.9960\n",
      "epoch: 76\n",
      "500/500 [==============================] - 36s 73ms/step - loss: 0.0155 - accuracy: 0.9948\n",
      "epoch: 77\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 0.0042 - accuracy: 0.9987\n",
      "epoch: 78\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 0.0239 - accuracy: 0.9917\n",
      "epoch: 79\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 0.0131 - accuracy: 0.9956\n",
      "epoch: 80\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 0.0034 - accuracy: 0.9990\n",
      "epoch: 81\n",
      "500/500 [==============================] - 37s 75ms/step - loss: 0.0122 - accuracy: 0.9958\n",
      "epoch: 82\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 0.0227 - accuracy: 0.9928\n",
      "epoch: 83\n",
      "500/500 [==============================] - 36s 72ms/step - loss: 0.0075 - accuracy: 0.9975\n",
      "epoch: 84\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 0.0084 - accuracy: 0.9971\n",
      "epoch: 85\n",
      "500/500 [==============================] - 36s 73ms/step - loss: 0.0215 - accuracy: 0.9924\n",
      "epoch: 86\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 0.0085 - accuracy: 0.9971\n",
      "epoch: 87\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 0.0098 - accuracy: 0.9967\n",
      "epoch: 88\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 0.0160 - accuracy: 0.9944\n",
      "epoch: 89\n",
      "500/500 [==============================] - 36s 73ms/step - loss: 0.0110 - accuracy: 0.9962\n",
      "epoch: 90\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 0.0086 - accuracy: 0.9971\n",
      "epoch: 91\n",
      "500/500 [==============================] - 36s 73ms/step - loss: 0.0144 - accuracy: 0.9944\n",
      "epoch: 92\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 0.0096 - accuracy: 0.9967\n",
      "epoch: 93\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 0.0063 - accuracy: 0.9980\n",
      "epoch: 94\n",
      "500/500 [==============================] - 36s 73ms/step - loss: 0.0176 - accuracy: 0.9941\n",
      "epoch: 95\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 0.0106 - accuracy: 0.9964\n",
      "epoch: 96\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 0.0094 - accuracy: 0.9965\n",
      "epoch: 97\n",
      "500/500 [==============================] - 36s 73ms/step - loss: 0.0101 - accuracy: 0.9964\n",
      "epoch: 98\n",
      "500/500 [==============================] - 36s 73ms/step - loss: 0.0110 - accuracy: 0.9962\n",
      "epoch: 99\n",
      "500/500 [==============================] - 36s 73ms/step - loss: 0.0116 - accuracy: 0.9958\n",
      "epoch: 100\n",
      "500/500 [==============================] - 36s 73ms/step - loss: 0.0102 - accuracy: 0.9963\n"
     ]
    }
   ],
   "source": [
    "# implement your code here.\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    print('epoch:', epoch + 1)\n",
    "    model_73.fit(x_train, y_train, batch_size=100, epochs=1, verbose=1)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print('epoch:', epoch + 1)\n",
    "    model_93.fit(x_train, y_train, batch_size=100, epochs=1, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Test your models. (5 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 7s 17ms/step - loss: 0.8490 - accuracy: 0.8665\n",
      "model_73-loss: 0.8490239977836609 model_73-acc: 0.8665000200271606\n",
      "313/313 [==============================] - 8s 21ms/step - loss: 0.8141 - accuracy: 0.8759\n",
      "model_93-loss: 0.8140944838523865 model_93-acc: 0.8758999705314636\n"
     ]
    }
   ],
   "source": [
    "# implement your code here.\n",
    "res = model_73.evaluate(x_test, y_test, verbose=1)\n",
    "print('model_73-loss:', str(res[0]), 'model_73-acc:', str(res[1]))\n",
    "res = model_93.evaluate(x_test, y_test, verbose=1)\n",
    "print('model_93-loss:', str(res[0]), 'model_93-acc:', str(res[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Load the pre-trained models from Keras and evaluate them. (15 marks)\n",
    "\n",
    "Use the pre-trained DenseNet-121 model from keras and fine-tune them by adding a few fc layers at the end. You should set the parameter weights='imagenet', rather than None, to use the pretrained weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n",
      "500/500 [==============================] - 16s 22ms/step - loss: 1.7543 - accuracy: 0.4048\n",
      "epoch: 2\n",
      "500/500 [==============================] - 11s 22ms/step - loss: 1.1328 - accuracy: 0.6085\n",
      "epoch: 3\n",
      "500/500 [==============================] - 11s 22ms/step - loss: 1.0749 - accuracy: 0.6283\n",
      "epoch: 4\n",
      "500/500 [==============================] - 11s 22ms/step - loss: 1.0469 - accuracy: 0.6358\n",
      "epoch: 5\n",
      "500/500 [==============================] - 11s 22ms/step - loss: 1.0308 - accuracy: 0.6418\n",
      "epoch: 6\n",
      "500/500 [==============================] - 11s 22ms/step - loss: 1.0171 - accuracy: 0.6472\n",
      "epoch: 7\n",
      "500/500 [==============================] - 11s 22ms/step - loss: 1.0089 - accuracy: 0.6489\n",
      "epoch: 8\n",
      "500/500 [==============================] - 11s 22ms/step - loss: 1.0029 - accuracy: 0.6499\n",
      "epoch: 9\n",
      "500/500 [==============================] - 11s 22ms/step - loss: 0.9950 - accuracy: 0.6541\n",
      "epoch: 10\n",
      "500/500 [==============================] - 11s 22ms/step - loss: 0.9911 - accuracy: 0.6543\n",
      "epoch: 11\n",
      "500/500 [==============================] - 11s 22ms/step - loss: 0.9877 - accuracy: 0.6571\n",
      "epoch: 12\n",
      "500/500 [==============================] - 11s 22ms/step - loss: 0.9859 - accuracy: 0.6551\n",
      "epoch: 13\n",
      "500/500 [==============================] - 11s 22ms/step - loss: 0.9808 - accuracy: 0.6591\n",
      "epoch: 14\n",
      "500/500 [==============================] - 11s 22ms/step - loss: 0.9787 - accuracy: 0.6593\n",
      "epoch: 15\n",
      "500/500 [==============================] - 11s 22ms/step - loss: 0.9759 - accuracy: 0.6604\n",
      "epoch: 16\n",
      "500/500 [==============================] - 11s 22ms/step - loss: 0.9748 - accuracy: 0.6594\n",
      "epoch: 17\n",
      "500/500 [==============================] - 11s 22ms/step - loss: 0.9725 - accuracy: 0.6603\n",
      "epoch: 18\n",
      "500/500 [==============================] - 11s 22ms/step - loss: 0.9689 - accuracy: 0.6631\n",
      "epoch: 19\n",
      "500/500 [==============================] - 11s 22ms/step - loss: 0.9679 - accuracy: 0.6632\n",
      "epoch: 20\n",
      "500/500 [==============================] - 11s 22ms/step - loss: 0.9647 - accuracy: 0.6636\n",
      "epoch: 21\n",
      "500/500 [==============================] - 11s 22ms/step - loss: 0.9645 - accuracy: 0.6632\n",
      "epoch: 22\n",
      "500/500 [==============================] - 11s 22ms/step - loss: 0.9627 - accuracy: 0.6644\n",
      "epoch: 23\n",
      "500/500 [==============================] - 11s 22ms/step - loss: 0.9617 - accuracy: 0.6665\n",
      "epoch: 24\n",
      "500/500 [==============================] - 11s 22ms/step - loss: 0.9596 - accuracy: 0.6667\n",
      "epoch: 25\n",
      "500/500 [==============================] - 11s 22ms/step - loss: 0.9581 - accuracy: 0.6665\n",
      "epoch: 26\n",
      "500/500 [==============================] - 11s 22ms/step - loss: 0.9571 - accuracy: 0.6681\n",
      "epoch: 27\n",
      "500/500 [==============================] - 11s 22ms/step - loss: 0.9582 - accuracy: 0.6664\n",
      "epoch: 28\n",
      "500/500 [==============================] - 11s 22ms/step - loss: 0.9550 - accuracy: 0.6672\n",
      "epoch: 29\n",
      "500/500 [==============================] - 11s 22ms/step - loss: 0.9542 - accuracy: 0.6684\n",
      "epoch: 30\n",
      "500/500 [==============================] - 11s 22ms/step - loss: 0.9519 - accuracy: 0.6681\n",
      "epoch: 31\n",
      "500/500 [==============================] - 11s 22ms/step - loss: 0.9501 - accuracy: 0.6685\n",
      "epoch: 32\n",
      "500/500 [==============================] - 11s 22ms/step - loss: 0.9500 - accuracy: 0.6691\n",
      "epoch: 33\n",
      "500/500 [==============================] - 11s 22ms/step - loss: 0.9496 - accuracy: 0.6695\n",
      "epoch: 34\n",
      "500/500 [==============================] - 11s 22ms/step - loss: 0.9479 - accuracy: 0.6686\n",
      "epoch: 35\n",
      "500/500 [==============================] - 11s 22ms/step - loss: 0.9485 - accuracy: 0.6683\n",
      "epoch: 36\n",
      "500/500 [==============================] - 11s 22ms/step - loss: 0.9461 - accuracy: 0.6701\n",
      "epoch: 37\n",
      "500/500 [==============================] - 11s 22ms/step - loss: 0.9459 - accuracy: 0.6706\n",
      "epoch: 38\n",
      "500/500 [==============================] - 11s 22ms/step - loss: 0.9455 - accuracy: 0.6706\n",
      "epoch: 39\n",
      "500/500 [==============================] - 11s 22ms/step - loss: 0.9448 - accuracy: 0.6707\n",
      "epoch: 40\n",
      "500/500 [==============================] - 11s 22ms/step - loss: 0.9422 - accuracy: 0.6713\n",
      "epoch: 41\n",
      "500/500 [==============================] - 11s 22ms/step - loss: 0.9409 - accuracy: 0.6732\n",
      "epoch: 42\n",
      "500/500 [==============================] - 11s 22ms/step - loss: 0.9413 - accuracy: 0.6719\n",
      "epoch: 43\n",
      "500/500 [==============================] - 11s 22ms/step - loss: 0.9410 - accuracy: 0.6726\n",
      "epoch: 44\n",
      "500/500 [==============================] - 11s 22ms/step - loss: 0.9388 - accuracy: 0.6723\n",
      "epoch: 45\n",
      "500/500 [==============================] - 11s 22ms/step - loss: 0.9404 - accuracy: 0.6725\n",
      "epoch: 46\n",
      "500/500 [==============================] - 11s 22ms/step - loss: 0.9376 - accuracy: 0.6722\n",
      "epoch: 47\n",
      "500/500 [==============================] - 11s 22ms/step - loss: 0.9371 - accuracy: 0.6746\n",
      "epoch: 48\n",
      "500/500 [==============================] - 11s 22ms/step - loss: 0.9371 - accuracy: 0.6728\n",
      "epoch: 49\n",
      "500/500 [==============================] - 11s 22ms/step - loss: 0.9368 - accuracy: 0.6725\n",
      "epoch: 50\n",
      "500/500 [==============================] - 11s 22ms/step - loss: 0.9378 - accuracy: 0.6722\n",
      "epoch: 1\n",
      "500/500 [==============================] - 46s 72ms/step - loss: 1.5002 - accuracy: 0.5401\n",
      "epoch: 2\n",
      "500/500 [==============================] - 36s 72ms/step - loss: 0.6260 - accuracy: 0.7858\n",
      "epoch: 3\n",
      "500/500 [==============================] - 36s 72ms/step - loss: 0.4325 - accuracy: 0.8507\n",
      "epoch: 4\n",
      "500/500 [==============================] - 36s 73ms/step - loss: 0.2851 - accuracy: 0.9012\n",
      "epoch: 5\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 0.1827 - accuracy: 0.9391\n",
      "epoch: 6\n",
      "500/500 [==============================] - 36s 73ms/step - loss: 0.1242 - accuracy: 0.9589\n",
      "epoch: 7\n",
      "500/500 [==============================] - 36s 73ms/step - loss: 0.0981 - accuracy: 0.9661\n",
      "epoch: 8\n",
      "500/500 [==============================] - 37s 75ms/step - loss: 0.0770 - accuracy: 0.9734\n",
      "epoch: 9\n",
      "500/500 [==============================] - 35s 71ms/step - loss: 0.0719 - accuracy: 0.9751\n",
      "epoch: 10\n",
      "500/500 [==============================] - 36s 71ms/step - loss: 0.0854 - accuracy: 0.9712\n",
      "epoch: 11\n",
      "500/500 [==============================] - 35s 71ms/step - loss: 0.0622 - accuracy: 0.9786\n",
      "epoch: 12\n",
      "500/500 [==============================] - 36s 71ms/step - loss: 0.0446 - accuracy: 0.9849\n",
      "epoch: 13\n",
      "500/500 [==============================] - 36s 72ms/step - loss: 0.0426 - accuracy: 0.9853\n",
      "epoch: 14\n",
      "500/500 [==============================] - 36s 72ms/step - loss: 0.0407 - accuracy: 0.9862\n",
      "epoch: 15\n",
      "500/500 [==============================] - 36s 72ms/step - loss: 0.0444 - accuracy: 0.9846\n",
      "epoch: 16\n",
      "500/500 [==============================] - 36s 71ms/step - loss: 0.0397 - accuracy: 0.9862\n",
      "epoch: 17\n",
      "500/500 [==============================] - 36s 72ms/step - loss: 0.0379 - accuracy: 0.9872\n",
      "epoch: 18\n",
      "500/500 [==============================] - 36s 72ms/step - loss: 0.0353 - accuracy: 0.9877\n",
      "epoch: 19\n",
      "500/500 [==============================] - 36s 72ms/step - loss: 0.0497 - accuracy: 0.9830\n",
      "epoch: 20\n",
      "500/500 [==============================] - 35s 71ms/step - loss: 0.0368 - accuracy: 0.9872\n",
      "epoch: 21\n",
      "500/500 [==============================] - 35s 71ms/step - loss: 0.0399 - accuracy: 0.9866\n",
      "epoch: 22\n",
      "500/500 [==============================] - 36s 71ms/step - loss: 0.0268 - accuracy: 0.9912\n",
      "epoch: 23\n",
      "500/500 [==============================] - 36s 71ms/step - loss: 0.0332 - accuracy: 0.9885\n",
      "epoch: 24\n",
      "500/500 [==============================] - 36s 73ms/step - loss: 0.0232 - accuracy: 0.9921\n",
      "epoch: 25\n",
      "500/500 [==============================] - 36s 72ms/step - loss: 0.0216 - accuracy: 0.9928\n",
      "epoch: 26\n",
      "500/500 [==============================] - 36s 71ms/step - loss: 0.0253 - accuracy: 0.9911\n",
      "epoch: 27\n",
      "500/500 [==============================] - 36s 72ms/step - loss: 0.0272 - accuracy: 0.9905\n",
      "epoch: 28\n",
      "500/500 [==============================] - 36s 72ms/step - loss: 0.0258 - accuracy: 0.9913\n",
      "epoch: 29\n",
      "500/500 [==============================] - 36s 71ms/step - loss: 0.0229 - accuracy: 0.9923\n",
      "epoch: 30\n",
      "500/500 [==============================] - 36s 71ms/step - loss: 0.0186 - accuracy: 0.9940\n",
      "epoch: 31\n",
      "500/500 [==============================] - 36s 71ms/step - loss: 0.0210 - accuracy: 0.9926\n",
      "epoch: 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 36s 71ms/step - loss: 0.0356 - accuracy: 0.9880\n",
      "epoch: 33\n",
      "500/500 [==============================] - 35s 71ms/step - loss: 0.0321 - accuracy: 0.9895\n",
      "epoch: 34\n",
      "500/500 [==============================] - 36s 71ms/step - loss: 0.0144 - accuracy: 0.9950\n",
      "epoch: 35\n",
      "500/500 [==============================] - 36s 72ms/step - loss: 0.0147 - accuracy: 0.9951\n",
      "epoch: 36\n",
      "500/500 [==============================] - 36s 72ms/step - loss: 0.0173 - accuracy: 0.9942\n",
      "epoch: 37\n",
      "500/500 [==============================] - 35s 71ms/step - loss: 0.0169 - accuracy: 0.9943\n",
      "epoch: 38\n",
      "500/500 [==============================] - 36s 72ms/step - loss: 0.0218 - accuracy: 0.9928\n",
      "epoch: 39\n",
      "500/500 [==============================] - 36s 72ms/step - loss: 0.0195 - accuracy: 0.9935\n",
      "epoch: 40\n",
      "500/500 [==============================] - 36s 72ms/step - loss: 0.0144 - accuracy: 0.9954\n",
      "epoch: 41\n",
      "500/500 [==============================] - 35s 70ms/step - loss: 0.0191 - accuracy: 0.9937\n",
      "epoch: 42\n",
      "500/500 [==============================] - 35s 71ms/step - loss: 0.0175 - accuracy: 0.9945\n",
      "epoch: 43\n",
      "500/500 [==============================] - 36s 71ms/step - loss: 0.0124 - accuracy: 0.9960\n",
      "epoch: 44\n",
      "500/500 [==============================] - 36s 71ms/step - loss: 0.0164 - accuracy: 0.9944\n",
      "epoch: 45\n",
      "500/500 [==============================] - 36s 72ms/step - loss: 0.0165 - accuracy: 0.9942\n",
      "epoch: 46\n",
      "500/500 [==============================] - 36s 72ms/step - loss: 0.0155 - accuracy: 0.9949\n",
      "epoch: 47\n",
      "500/500 [==============================] - 36s 72ms/step - loss: 0.0153 - accuracy: 0.9948\n",
      "epoch: 48\n",
      "500/500 [==============================] - 36s 71ms/step - loss: 0.0121 - accuracy: 0.9960\n",
      "epoch: 49\n",
      "500/500 [==============================] - 36s 73ms/step - loss: 0.0250 - accuracy: 0.9915\n",
      "epoch: 50\n",
      "500/500 [==============================] - 36s 72ms/step - loss: 0.0161 - accuracy: 0.9946\n",
      "313/313 [==============================] - 9s 23ms/step - loss: 0.8334 - accuracy: 0.8572\n",
      "pre_trained_model-loss: 0.8333893418312073 pre_trained_model-acc: 0.857200026512146\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.densenet import DenseNet121\n",
    "\n",
    "# implement your code here.\n",
    "# 构建不带分类器的预训练模型\n",
    "base_model = keras.applications.DenseNet121(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
    "# 添加全局平均池化层\n",
    "x = base_model.output\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "# 添加一个分类器，我们有10个类\n",
    "predictions = layers.Dense(10, activation='softmax')(x)\n",
    "# 构建我们需要训练的完整模型\n",
    "pre_trained_model = keras.Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# 首先，我们只训练顶部的几层（随机初始化的层）\n",
    "# 锁住所有 base_model 的卷积层\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# 编译模型（一定要在锁层以后操作）\n",
    "pre_trained_model.compile(optimizer=keras.optimizers.Adam(),\n",
    "                          loss='categorical_crossentropy',\n",
    "                          metrics=['accuracy'])\n",
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "    print('epoch:', epoch + 1)\n",
    "    pre_trained_model.fit(x_train, y_train, batch_size=100, epochs=1, verbose=1)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "# 让我们设置一个很低的学习率，使用 Adam 来微调\n",
    "pre_trained_model.compile(optimizer=keras.optimizers.Adam(lr=0.0001),\n",
    "                          loss='categorical_crossentropy',\n",
    "                          metrics=['accuracy'])\n",
    "for epoch in range(epochs):\n",
    "    print('epoch:', epoch + 1)\n",
    "    pre_trained_model.fit(x_train, y_train, batch_size=100, epochs=1, verbose=1)\n",
    "res = pre_trained_model.evaluate(x_test, y_test, verbose=1)\n",
    "print('pre_trained_model-loss:', str(res[0]), 'pre_trained_model-acc:', str(res[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Analysis your results. (20 marks)\n",
    "Compare the performance of your models with the following analysis. Both English and Chinese answers are acceptable.\n",
    "1. Is your implementation of DenseNet-93 better than DenseNet-73? If yes, how is the improvement? If no, try to figure the reason out based on your experiments. (10 marks)\n",
    "\n",
    "Answer:\n",
    "\n",
    "2. Compare the results of your implementations with the pre-trained DenseNet-121 models from Keras. (10 marks)\n",
    "\n",
    "Answer:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1、在第一次训练中，我将epoch设置为10，在10个epoch的训练过程中，DenseNet-93并没有取得比DenseNet-73更好的结果，结果如下所示：\n",
    "\n",
    "313/313 [==============================] - 7s 18ms/step - loss: 0.5753 - accuracy: 0.8261\n",
    "\n",
    "model_73-loss: 0.5752847194671631 model_73-acc: 0.8260999917984009\n",
    "\n",
    "313/313 [==============================] - 8s 21ms/step - loss: 0.6818 - accuracy: 0.8069\n",
    "\n",
    "model_93-loss: 0.6818189024925232 model_93-acc: 0.8069000244140625\n",
    "\n",
    "我认为是更深层次的网络可能更加难以训练，所以，我将训练的epoch调整到了100，果然效果有了出色的提升：\n",
    "\n",
    "313/313 [==============================] - 7s 17ms/step - loss: 0.8490 - accuracy: 0.8665\n",
    "\n",
    "model_73-loss: 0.8490239977836609 model_73-acc: 0.8665000200271606\n",
    "\n",
    "313/313 [==============================] - 8s 21ms/step - loss: 0.8141 - accuracy: 0.8759\n",
    "\n",
    "model_93-loss: 0.8140944838523865 model_93-acc: 0.8758999705314636\n",
    "\n",
    "在100个epoch的训练中，DenseNet-93在测试集上达到了87.6%的精确度，比DenseNet-73的86.6%的效果要好。但总体来说，效果差距并不大。\n",
    "\n",
    "说明低层的DenseNet在这个任务上已经能够取得很好的效果。\n",
    "\n",
    "2、在使用pre-trained DenseNet-121的过程中，我首先构建了不带分类器的DenseNet-121模型，然后增加了pooling层和softmax层，首先对原来的DenseNet模型进行锁定参数的操作，使用5个epoch对随机的参数进行调整，然后取消锁定，使用5个epoch对所有参数进行了调整，得到的结果如下：\n",
    "\n",
    "pre_trained_model-loss: 0.6386442184448242 pre_trained_model-acc: 0.8180000185966492\n",
    "\n",
    "可以看到，效果和我们自己实现的模型相近，我刚开始认为是训练次数不够导致的：\n",
    "\n",
    "然后对原来的DenseNet模型进行锁定参数的操作，使用50个epoch对随机的参数进行调整，然后取消锁定，使用50个epoch对所有参数进行了调整，得到的结果如下：\n",
    "\n",
    "pre_trained_model-loss: 0.8333893418312073 pre_trained_model-acc: 0.857200026512146\n",
    "\n",
    "可以看到，效果还不如自己实现的enseNet-93和DenseNet-73，我认为是在模型的调参上和一些trick上，自己实现的模型在这个任务上更出色。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
